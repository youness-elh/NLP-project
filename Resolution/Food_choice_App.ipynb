{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sn\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NLP\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "stopwords = set(STOPWORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.externals import joblib\n",
    "from sklearn import linear_model\n",
    "import sklearn.preprocessing\n",
    "import sklearn.linear_model\n",
    "import sklearn.pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtCore import QAbstractTableModel, Qt\n",
    "from PyQt5 import QtWidgets, uic, QtGui,QtCore\n",
    "from PyQt5.QtWidgets import QApplication, QWidget, QPushButton, QMessageBox,QDesktopWidget\n",
    "from PyQt5.QtGui import QIcon\n",
    "import sys\n",
    "from PyQt5 import QtWidgets\n",
    "import os\n",
    "from PyQt5.QtWidgets import QMainWindow, QApplication\n",
    "from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas\n",
    "from matplotlib.backends.backend_qt5agg import NavigationToolbar2QT as NavigationToolbar\n",
    "from PyQt5.QtWidgets import QDialog, QApplication, QPushButton, QVBoxLayout,QMessageBox,QProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Data set import:***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Dataset'...\n",
      "fatal: unable to access 'https://github.com/youness-elh/Dataset/': Failed to connect to github.com port 443: Connection refused\n",
      "Der Befehl \"ls\" ist entweder falsch geschrieben oder\n",
      "konnte nicht gefunden werden.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"It is not necessary to re-rerun this cells after a %reset\"\"\"\n",
    "\n",
    "\"to load assets on the server (if it was not already done)\"\n",
    "import os\n",
    "if not os.path.exists(\"Dataset\"):\n",
    "    !git clone https://github.com/youness-elh/Dataset\n",
    "\n",
    "\"checking: directories 'dataframe','img'  must appear\"\n",
    "!ls Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Objective:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Food choices and preferences of college students***\n",
    "\n",
    "Dans ce notebooke j'ai essayé de mettre en oeuvre l'ensemble des modèles `pickelés` dans le notebook `Food_choice_pipeline` sous forme d'interface graphique. l'idée est de faciliter l'étude des diffèrents sénarios possibles tout en rèpondant à plusieurs question. Pour l'instant l'application rèsume seulememt la rèponse à la question:\n",
    "\n",
    "* Quelle est la relation entre les autres descipteurs et la note de l´êleve?\n",
    "\n",
    "Sans interaction avec l'utilisateur...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline de prétraitement et Interface graphique:\n",
    "\n",
    "Notre input X est tous les descpteurs décrits auparavant et notre output Y est le ´GPA´. \n",
    "\n",
    "Nous avons enpaqueté tous les prétraitement dans un pipeline, qui sera aussi appliqué au jeu test (sauf que nous ne fiterons jamais sur test).\n",
    "\n",
    "Les réesultats sont présentés sous forme de graphes pour le jeu ´fité´ et ensuite celui gardé pour le test.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyPipeline():\n",
    "        \n",
    "    \"\"\"this method is automaticaly called we buid the object i.e. we write pipeline=MyPipeLine() \"\"\"\n",
    "    def __init__(self,path_to_data,fill_with= 'median'):\n",
    "        \n",
    "        self.path = path_to_data\n",
    "        self.fill_with = fill_with\n",
    "        \n",
    "        self._scaler = sklearn.preprocessing.StandardScaler()\n",
    "        self._was_fit = False\n",
    "        self._was_fit_strat = False\n",
    "        self._was_read = False\n",
    "        self._was_cleaned = False\n",
    "        \n",
    "        self.X_names=None\n",
    "        self.df = None\n",
    "        self.strat_test_set = None\n",
    "        self.strat_train_set = None\n",
    "        self.test_set = None\n",
    "        self.train_set = None\n",
    "        \n",
    "        '''output'''\n",
    "        self.X_train = None\n",
    "        self.X_test = None\n",
    "        self.Y_train = None\n",
    "        self.Y_test = None\n",
    "           \n",
    "    def read_data(self):\n",
    "        self._was_read = True\n",
    "        self.df = pd.read_csv(self.path)\n",
    "        self.data = self.df.copy()\n",
    "        \n",
    "    def clean_data(self,df,feature,feature_type,fill_with = 'median'):\n",
    "    \n",
    "        def remove_point(x):\n",
    "            if x =='.':\n",
    "                return ''\n",
    "            else:\n",
    "                return x\n",
    "    \n",
    "        if df[feature].dtype == object :\n",
    "            df[feature] = df[feature].str.replace('[a-z]|[A-Z]|\\,|\\\"|\\;|\\'|\\s','')\n",
    "            df[feature] = df[feature].apply(remove_point)\n",
    "            df[feature].replace(to_replace='',value=0,inplace=True)\n",
    "            #print('In \"'+str(feature)+'\" feature some non sens words were deleted')\n",
    "\n",
    "        if df[feature].isnull().any():\n",
    "            df[feature].fillna(0,inplace=True)\n",
    "            #print('In \"'+str(feature)+'\" feature some nan value were replaced by the '+ str(fill_with))\n",
    "\n",
    "        else:\n",
    "            #print('\"'+str(feature)+'\" feature was already cleaned!')\n",
    "            pass\n",
    "\n",
    "        df[feature] = df[feature].astype(feature_type)\n",
    "        mean = round(df[feature].mean(),1) if fill_with =='mean' else round(df[feature].median(),1)\n",
    "        df[feature].replace(to_replace=0,value=mean,inplace=True) \n",
    "\n",
    "        if feature == 'weight':\n",
    "             df[feature] = df[feature].apply(lambda x : round(x/2.205,3))\n",
    "\n",
    "        return df\n",
    "    \n",
    "    def All_no_nlp_clean(self):\n",
    "        self._was_cleaned = True\n",
    "        \n",
    "        if self._was_read == False:\n",
    "            self.read_data()\n",
    "            \n",
    "        try:\n",
    "            open_ended_columns = ['comfort_food','comfort_food_reasons','diet_current','eating_changes','father_profession','mother_profession','fav_cuisine','food_childhood','healthy_meal','ideal_diet','meals_dinner_friend','type_sports']\n",
    "            df_no_nlp = self.df.drop(open_ended_columns,axis=1)\n",
    "        except Exception:\n",
    "            pass\n",
    "        features = df_no_nlp.columns\n",
    "        n =len(features)\n",
    "        for i,f in enumerate(features):\n",
    "            #print('-----'+str(i+1)+'th feature begins out of '+str(n)+' features-----')\n",
    "            df_no_nlp = self.clean_data(df_no_nlp,f,'float','median')\n",
    "\n",
    "        self.df = df_no_nlp\n",
    "            \n",
    "    def delete_corr_feat(self):\n",
    "        try:\n",
    "            self.df.drop(\"comfort_food_reasons_coded\", axis=1, inplace=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        \n",
    "    def cleaned_nlp(self,feature = 'comfort_food'):\n",
    "        open_ended_columns = ['comfort_food','comfort_food_reasons','diet_current','eating_changes','father_profession','mother_profession','fav_cuisine','food_childhood','healthy_meal','ideal_diet','meals_dinner_friend','type_sports']\n",
    "        df_nlp = self.data.loc[:,open_ended_columns]\n",
    "        \n",
    "        def clean_text(text):\n",
    "            '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''\n",
    "            text = text.lower()\n",
    "            text = re.sub('\\[.*?\\]', '', text)\n",
    "            text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "            text = re.sub('\\w*\\d\\w*', '', text)\n",
    "            text = re.sub('[‘’“”…]', '', text)\n",
    "            text = re.sub('\\n', '', text)\n",
    "            return text\n",
    "    \n",
    "        for f in open_ended_columns:\n",
    "            df_nlp[f] = pd.DataFrame(df_nlp[f].apply(lambda x: clean_text(str(x))))\n",
    "            \n",
    "        cv = CountVectorizer(stop_words='english')\n",
    "        data_cv = cv.fit_transform(df_nlp[feature])\n",
    "        data_dtm = pd.DataFrame(data_cv.toarray(), columns=cv.get_feature_names())\n",
    "        data_dtm.index = df_nlp.index\n",
    "        \n",
    "        return df_nlp, data_dtm  \n",
    "    \n",
    "    def plot_top_words(self,feature = 'comfort_food'):\n",
    "        df_nlp, data_dtm = self.cleaned_nlp(feature)\n",
    "        \n",
    "        try:\n",
    "            maskComfy = 255-np.array(Image.open( \"../heart.png\"))\n",
    "        except Exception:\n",
    "            print('mask not available')\n",
    "            pass\n",
    "\n",
    "        wordcloud = (WordCloud(width=1440, height=1080, relative_scaling=0.5,\n",
    "        stopwords=stopwords,mask=maskComfy,max_words=1000,background_color='white').generate_from_frequencies(df_nlp[feature].value_counts()))\n",
    "\n",
    "        fig = plt.figure(1,figsize=(15, 15))\n",
    "        plt.imshow(wordcloud,interpolation=\"gaussian\")\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "        \n",
    "    \n",
    "    def convert_to_cat(self):\n",
    "        \n",
    "        features = ['calories_chicken','calories_scone', 'tortilla_calories', 'turkey_calories','waffle_calories']\n",
    "        def change_to_cat(x):\n",
    "            if x == 265.0 or x == 107.0 or x == 580.0 or x == 345.0  or x == 575.0:\n",
    "                x =1\n",
    "            elif x == 430.0 or x == 315.0  or x == 725.0 or x == 500.0  or x == 760.0:\n",
    "                x=2\n",
    "            elif x == 610.0 or x == 420.0  or x == 940.0 or x == 690.0  or x == 900.0:\n",
    "                x=3\n",
    "            elif x == 720.0 or x == 980.0  or x == 1165.0 or x == 850.0  or x == 1315.0:\n",
    "                x=4\n",
    "            return int(x)\n",
    "\n",
    "        for _,f in enumerate(features):\n",
    "            self.df[f] = self.df[f].apply(change_to_cat)\n",
    "            self.df[f] = self.df[f].astype('int')\n",
    "        \n",
    "    \n",
    "    def standardize(self):\n",
    "        num_columns = ['GPA','weight']\n",
    "        scaler=StandardScaler()\n",
    "        df_num_st=scaler.fit_transform(self.df[num_columns])\n",
    "        self.df[num_columns] = pd.DataFrame(df_num_st)\n",
    "        \n",
    "    def x_train_test_random(self):\n",
    "        if not self._was_fit:\n",
    "            self.train_set, self.test_set = train_test_split(self.df, test_size=0.2, random_state=42)\n",
    "        \n",
    "    '''Dans notre jeu de donnée, le 'GPA' (Note) est un descripteur naturellement pour stratifier la population.''' \n",
    "    def x_train_test_strat(self, plot=False):\n",
    "        \n",
    "        if not self._was_fit_strat:\n",
    "        \n",
    "            self.df[\"GPA_cat\"] = np.ceil(self.df[\"GPA\"]/1.5)\n",
    "            self.df[\"GPA_cat\"].where(self.df[\"GPA\"] < 4,4.0, inplace=True)\n",
    "            split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "            for train_index, test_index in split.split(self.df, self.df[\"GPA_cat\"]):\n",
    "                self.strat_train_set = self.df.loc[train_index]\n",
    "                self.strat_test_set = self.df.loc[test_index]\n",
    "                \n",
    "            if plot :\n",
    "                freq=self.df[\"GPA_cat\"].value_counts()\n",
    "                # ou bien avec numpy\n",
    "                # freq=np.unique(housing_0[\"income_cat\"].values,return_counts=True)\n",
    "                plt.bar(freq.index,freq.values);\n",
    "                plt.show();\n",
    "\n",
    "            self._was_fit_strat = True\n",
    "            try:\n",
    "                for set_ in (self.strat_train_set, self.strat_test_set):\n",
    "                    set_.drop(\"GPA_cat\", axis=1, inplace=True)\n",
    "                    \n",
    "                self.df.drop(\"GPA_cat\", axis=1, inplace=True)\n",
    "            except Exception:\n",
    "                pass\n",
    "\n",
    "        \n",
    "    def input_output_numpy(self,feature_y = 'GPA',strat=True,conv_stand = True):\n",
    "        \n",
    "        if not self._was_read:\n",
    "            self.read_data()\n",
    "            #print('read')\n",
    "\n",
    "        if not self._was_cleaned:\n",
    "            self.All_no_nlp_clean()\n",
    "            #print('cleaned')\n",
    "         \n",
    "        if conv_stand:\n",
    "            '''convert to cat and standardize'''\n",
    "            self.convert_to_cat()\n",
    "            self.standardize()\n",
    "            \n",
    "        if strat == True:\n",
    "            self.x_train_test_strat(False)\n",
    "            self.X_test = self.strat_test_set.copy()\n",
    "            self.X_train = self.strat_train_set.copy()\n",
    "            \n",
    "        else:\n",
    "            self.x_train_test_random()\n",
    "            self.X_test = self.test_set\n",
    "            self.X_train = self.train_set\n",
    "            \n",
    "            \n",
    "        self.Y_train = self.X_train[feature_y].values.reshape(-1)\n",
    "        self.Y_test = self.X_test[feature_y].values.reshape(-1)\n",
    "        \n",
    "        self.X_train = self.X_train.drop(feature_y, axis=1, inplace=False)\n",
    "        self.X_names = self.X_train.columns.values\n",
    "        self.X_train = np.array(self.X_train)\n",
    "        self.X_test = self.X_test.drop(feature_y, axis=1, inplace=False)\n",
    "        self.X_test = np.array(self.X_test) \n",
    "        #print(self.Y_test.shape,self.X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npath_to_data = \\'..//food_coded.csv\\'\\nfill_with = \\'median\\'\\nobj = MyPipeline(path_to_data ,fill_with)\\n\\nobj.input_output_numpy()\\n\\nX_train,Y_train=obj.X_train,obj.Y_train\\nX_test,Y_test=obj.X_test,obj.Y_test\\nX_names=obj.X_names\\n\\n\"\"\" we check that MyPipeline.input_output_numpy() make the same job as our exploratory job.\"\"\"\\nprint(\\'--------X_test-------- \\n\\',X_test[:5,:10])\\nprint(\\'--------X_train-------- \\n\\',X_train[:5,:10])\\nprint(\"X_names\\n\",X_names[:10])\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "path_to_data = '..//food_coded.csv'\n",
    "fill_with = 'median'\n",
    "obj = MyPipeline(path_to_data ,fill_with)\n",
    "\n",
    "obj.input_output_numpy()\n",
    "\n",
    "X_train,Y_train=obj.X_train,obj.Y_train\n",
    "X_test,Y_test=obj.X_test,obj.Y_test\n",
    "X_names=obj.X_names\n",
    "\n",
    "\"\"\" we check that MyPipeline.input_output_numpy() make the same job as our exploratory job.\"\"\"\n",
    "print('--------X_test-------- \\n',X_test[:5,:10])\n",
    "print('--------X_train-------- \\n',X_train[:5,:10])\n",
    "print(\"X_names\\n\",X_names[:10])\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Plot_Window(QDialog):\n",
    "    def __init__(self, parent=None):\n",
    "        super(Plot_Window, self).__init__()\n",
    "        self.data = parent\n",
    "        self.constructor() \n",
    "        # Just some button connected to `plot` method\n",
    "        self.button = QPushButton('Plot')\n",
    "        self.button.clicked.connect(self.gui_plot)\n",
    "\n",
    "        # set the layout\n",
    "        layout = QVBoxLayout()\n",
    "        layout.addWidget(self.toolbar)\n",
    "        layout.addWidget(self.canvas)\n",
    "        layout.addWidget(self.button)\n",
    "        #layout.addWidget(self.button1)\n",
    "        self.setLayout(layout)\n",
    "        self.setWindowTitle('Plot')\n",
    "        \n",
    "        #self.show()\n",
    "        \n",
    "    def constructor(self):\n",
    "        \n",
    "        ''' To which purpose?  '''\n",
    "        box = QMessageBox()\n",
    "        box.setIcon(QMessageBox.Question)\n",
    "        box.setWindowTitle('Figure size!')\n",
    "        box.setStandardButtons(QMessageBox.Yes)\n",
    "        Default = box.button(QMessageBox.Yes)\n",
    "        Default.setText('Default')\n",
    "        box.exec_()\n",
    "\n",
    "        if box.clickedButton() == Default:\n",
    "        # YES pressed\n",
    "            # a figure instance to plot on\n",
    "            self.figure = plt.figure()\n",
    "            self.afont = {'fontname':'Arial'}\n",
    "            self.tfont = self.afont#{'fontname':'Arial'}\n",
    "            self.canvas = FigureCanvas(self.figure)\n",
    "\n",
    "            self.toolbar = NavigationToolbar(self.canvas, self)\n",
    "        \n",
    "    def gui_plot(self):\n",
    "\n",
    "        # instead of ax.hold(False)\n",
    "        self.figure.clear()\n",
    "\n",
    "        # create an axis\n",
    "        ax = self.figure.add_subplot(111)\n",
    "\n",
    "        # plot data\n",
    "        self.data.plot(ax=ax);\n",
    "\n",
    "        # refresh canvas\n",
    "        self.figure.tight_layout()\n",
    "        self.canvas.draw();\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class main_window_gui(QMainWindow):\n",
    "    def __init__(self,path,fill_with):\n",
    "        \n",
    "        self.path = path\n",
    "        self.fill_with = fill_with\n",
    "        \n",
    "        '''Load the ui'''\n",
    "        QMainWindow.__init__(self)\n",
    "        self.call = uic.loadUi('mainwindow_0.ui', self) \n",
    "        \n",
    "        '''Linear regression'''\n",
    "        self.lin1 = self.call.action_algo\n",
    "        self.lin1.triggered.connect(self.Algo1)\n",
    "        \n",
    "        '''decision tree'''\n",
    "        self.tree = self.call.action_tree\n",
    "        self.tree.triggered.connect(self.Algo2)\n",
    "        \n",
    "        '''random forest'''\n",
    "        self.forest = self.call.action_forest\n",
    "        self.forest.triggered.connect(self.Algo3)\n",
    "\n",
    "        self.show()\n",
    "        \n",
    "    def Algo1(self):\n",
    "        obj = MyPipeline(self.path ,self.fill_with)\n",
    "        obj.input_output_numpy()\n",
    "        \n",
    "        X_train,Y_train=obj.X_train,obj.Y_train\n",
    "        X_test,Y_test=obj.X_test,obj.Y_test\n",
    "        X_names=obj.X_names\n",
    "        \n",
    "        #try:\n",
    "        best_model = joblib.load(\"my_model_linear.pkl\") \n",
    "        Y_test_hat = best_model.predict(X_test)\n",
    "        df=pd.DataFrame({\"Y_test_hat_lin\":Y_test_hat[:],\"Y_test\":Y_test[:]})\n",
    "        window = Plot_Window(df)\n",
    "        window.show()\n",
    "        Y_train_hat = best_model.predict(X_train)\n",
    "        df=pd.DataFrame({\"Y_train_hat_lin\":Y_train_hat[:],\"Y_train\":Y_train[:]})\n",
    "        window = Plot_Window(df)\n",
    "        window.show()\n",
    "        #except Exception:\n",
    "        #buttonReply = QMessageBox.critical(self, \n",
    "        #'Error message', \"File could not be open\")\n",
    "                             \n",
    "    def Algo2(self):\n",
    "        obj = MyPipeline(self.path ,self.fill_with)\n",
    "        obj.input_output_numpy()\n",
    "        \n",
    "        X_train,Y_train=obj.X_train,obj.Y_train\n",
    "        X_test,Y_test=obj.X_test,obj.Y_test\n",
    "        X_names=obj.X_names\n",
    "        \n",
    "        try:\n",
    "            best_model = joblib.load(\"my_model_tree.pkl\") \n",
    "            Y_test_hat = best_model.predict(X_test)\n",
    "            df=pd.DataFrame({\"Y_test_hat_tree\":Y_test_hat[:],\"Y_test\":Y_test[:]})\n",
    "            window = Plot_Window(df)\n",
    "            window.show()\n",
    "            Y_train_hat = best_model.predict(X_train)\n",
    "            df=pd.DataFrame({\"Y_train_hat_tree\":Y_train_hat[:],\"Y_train\":Y_train[:]})\n",
    "            window = Plot_Window(df)\n",
    "            window.show()\n",
    "        except Exception:\n",
    "            buttonReply = QMessageBox.critical(self, \n",
    "            'Error message', \"File could not be open\")\n",
    "    def Algo3(self):\n",
    "        obj = MyPipeline(self.path ,self.fill_with)\n",
    "        obj.input_output_numpy()\n",
    "        \n",
    "        X_train,Y_train=obj.X_train,obj.Y_train\n",
    "        X_test,Y_test=obj.X_test,obj.Y_test\n",
    "        X_names=obj.X_names\n",
    "        \n",
    "        try:\n",
    "            best_model = joblib.load(\"my_model_forest.pkl\") \n",
    "            Y_test_hat = best_model.predict(X_test)\n",
    "            df=pd.DataFrame({\"Y_test_hat_forest\":Y_test_hat[:],\"Y_test\":Y_test[:]})\n",
    "            window = Plot_Window(df)\n",
    "            window.show()\n",
    "            Y_train_hat = best_model.predict(X_train)\n",
    "            df=pd.DataFrame({\"Y_train_hat_forest\":Y_train_hat[:],\"Y_train\":Y_train[:]})\n",
    "            window = Plot_Window(df)\n",
    "            window.show()\n",
    "        except Exception:\n",
    "            buttonReply = QMessageBox.critical(self, \n",
    "            'Error message', \"File could not be open\")\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(path,fill_with):\n",
    "    app = QtWidgets.QApplication(sys.argv) \n",
    "    window = main_window_gui(path,fill_with)\n",
    "    app.exec_() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '..//food_coded.csv'\n",
    "fill_with = 'median'\n",
    "main(path,fill_with);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
